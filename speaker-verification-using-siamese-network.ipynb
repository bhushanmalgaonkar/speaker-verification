{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speaker-verification-using-siamese-network.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yslH5PtB5YLH",
        "colab_type": "code",
        "outputId": "cf3238f2-6a8f-4912-cadd-79ed5b6c2b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4BLdItx66Rlv",
        "colab_type": "code",
        "outputId": "9cd14df0-2416-4bb8-e512-c9958959d801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.28.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dY8NyBq06SFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import pickle\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kqoi5cc16T_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pr3Fh6Z96wVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read and transform data\n",
        "\n",
        "Convert raw byte stream into useful feature space. STFT on the signals serves the initial feature extraction process"
      ]
    },
    {
      "metadata": {
        "id": "IvDw-ijN5v0G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_path = './drive/My Drive/Colab Notebooks/hw4/speaker-verification/'\n",
        "train_path = base_path + 'hw4_trs.pkl'\n",
        "test_path = base_path + 'hw4_tes.pkl'\n",
        "\n",
        "base_path_model = base_path + 'model/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpNd1Zi56bi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(train_path, 'rb') as f:\n",
        "  train_raw = pickle.load(f)\n",
        "\n",
        "with open(test_path, 'rb') as f:\n",
        "  test_raw = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2hLaf5X65hB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "trs.pkl contains an 500×16,180 matrix, whose row is a speech signal with 16,180 samples. They are\n",
        "the returned vectors from the librosa.load function. Similarly, tes.pkl holds a 200×22,631 matrix"
      ]
    },
    {
      "metadata": {
        "id": "ttwIhH6i66EI",
        "colab_type": "code",
        "outputId": "b9c59d04-7545-4d7b-8b13-589056b97104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_raw.shape, test_raw.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((500, 16180), (200, 22631))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "R2BM7QsV7WYD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert into audio (.wav file) for checking manually"
      ]
    },
    {
      "metadata": {
        "id": "9H81tr6D7b6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i in range(train_raw.shape[0]):\n",
        "#   librosa.output.write_wav(base_path + 'trs/trs' + ('0000' + str(i))[-4:] + '.wav', train_raw[i], 16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ps_uKZeM8NhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i in range(test_raw.shape[0]):\n",
        "#   librosa.output.write_wav(base_path + 'tes/tes' + ('0000' + str(i))[-4:] + '.wav', test_raw[i], 16000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hm8h0p86mF4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extract features using STFT"
      ]
    },
    {
      "metadata": {
        "id": "wsiuXvox6meZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_complex = np.array([librosa.stft(x, n_fft=1024, hop_length=512).T for x in train_raw])\n",
        "test_complex = np.array([librosa.stft(x, n_fft=1024, hop_length=512).T for x in test_raw])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s65BSNaT4XTZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = np.abs(train_complex)\n",
        "test = np.abs(test_complex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WrdcMtTd57Mp",
        "colab_type": "code",
        "outputId": "3576fe83-3fd0-4c92-cb21-aab9de6c4efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((500, 32, 513), (200, 45, 513))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "yGoPCmQw88_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate mini-batches"
      ]
    },
    {
      "metadata": {
        "id": "EcDhqpcu8chH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Structure of training data\n",
        "\n",
        "The training matrix is ordered by speakers. Each speaker has 10 utterances, and there are 50 such\n",
        "speakers (that’s why there are 500 rows). Similarly, the test set has 20 speakers, each of which is with\n",
        "10 utterances."
      ]
    },
    {
      "metadata": {
        "id": "xoPLr-ACE13o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samples_per_class = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xqSBYCI7LCq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Procedure to generate mini-batches\n",
        "\n",
        "1. Randomly sample L pairs of utterances from the ten utterance of the first speaker. In theory, there are $10 \\choose 2$= 45 pairs you can sample from. You can use all 45 of them if you want. These are the positive examples in your first minibatch\n",
        "\n",
        "2. Randomly sample L utterances from the 49 training speakers. Using them and the ten utterances of\n",
        "the first speaker, form another set of L pairs. If L > 10, you’ll need to repeatedly use the first speaker’s\n",
        "utterance (i.e. sampling with replacement). This set is your negative examples, each of whose pair\n",
        "contains an utterance from the first speaker and a random utterance spoken by a different speaker.\n",
        "\n",
        "3. In this first minibatch, you have 2L pairs of utterances.\n",
        "\n",
        "4. Repeat this process for the other training speakers, so that each speaker is represented by L positive\n",
        "pairs and L negative pairs. By doing so, you can form 50 minibatches with a balanced number of\n",
        "positive and negative pair"
      ]
    },
    {
      "metadata": {
        "id": "JwBYGb-i5iQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_length = 50\n",
        "num_features = 513"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFDD7y3b5DXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pad_zeros(stft):\n",
        "  stft_val = np.zeros((max_length, num_features))\n",
        "  stft_val[:stft.shape[0], :stft.shape[1]] = stft\n",
        "  return stft_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fNIWxX-OAOAC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "data: train/test\n",
        "batch_size: return batch_size number of positive and another batch_size number of negative pairs\n",
        "stick: if true, one training class will be common across positive and negative pairs\n",
        "\n",
        "returns:\n",
        "x: list of pairs\n",
        "y: 1 for positive pairs, 0 for negative\n",
        "'''\n",
        "def next_batch(data, batch_size, stick=False):\n",
        "  x1, x2, l1, l2, y = [], [], [], [], []\n",
        "  \n",
        "  num_classes = len(data) // samples_per_class\n",
        "  base = np.random.randint(num_classes)\n",
        "  \n",
        "  # generate positive pairs\n",
        "  for _ in range(batch_size):\n",
        "    # randomly select idx_0 only if stick is false\n",
        "    if not stick:\n",
        "      base = np.random.randint(num_classes)\n",
        "      \n",
        "    idx_0, idx_1 = base * samples_per_class + np.random.choice(np.arange(samples_per_class), size=2, replace=False)\n",
        "    x1.append(pad_zeros(data[idx_0]))\n",
        "    x2.append(pad_zeros(data[idx_1]))\n",
        "    l1.append(data[idx_0].shape[0])\n",
        "    l2.append(data[idx_1].shape[0])\n",
        "    y.append(1)\n",
        "#     print(idx_0, idx_1, 1)\n",
        "    \n",
        "  # generate negative pairs\n",
        "  for _ in range(batch_size):\n",
        "    # randomly select idx_0 only if stick is false\n",
        "    if not stick:\n",
        "      base = np.random.randint(num_classes)\n",
        "    \n",
        "    # make sure neg_base is not same as base\n",
        "    while True:\n",
        "      neg_base = np.random.randint(num_classes)\n",
        "      if neg_base != base:\n",
        "        break\n",
        "      \n",
        "    idx_0 = base * samples_per_class + np.random.randint(samples_per_class)\n",
        "    idx_1 = neg_base * samples_per_class + np.random.randint(samples_per_class)\n",
        "    \n",
        "    x1.append(pad_zeros(train[idx_0]))\n",
        "    x2.append(pad_zeros(train[idx_1]))\n",
        "    l1.append(train[idx_0].shape[0])\n",
        "    l2.append(train[idx_1].shape[0])\n",
        "    y.append(0)\n",
        "#     print(idx_0, idx_1, 0)\n",
        "    \n",
        "  return np.array(x1), np.array(x2), np.array(l1), np.array(l2), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVVbymY8cuAx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create model"
      ]
    },
    {
      "metadata": {
        "id": "K2E9VhP7uqxf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_hidden = 256\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDRUnq3hqgkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using this implementation as reference https://github.com/ardiya/siamesenetwork-tensorflow/blob/master/train.py\n",
        "\n",
        "def model(inp, reuse):\n",
        "  with tf.name_scope('model'):\n",
        "    \n",
        "    with tf.variable_scope('lstm_1') as scope:\n",
        "      cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(num_hidden, reuse=reuse))\n",
        "      output, state = tf.nn.dynamic_rnn(cell, inp, dtype=tf.float32)\n",
        "      \n",
        "#     with tf.variable_scope('conv_1') as scope:\n",
        "#       conv_1 = tf.contrib.layers.conv2d(inp, 16, [1, 3], activation_fn=tf.nn.relu, padding='same', \\\n",
        "# \t\t        weights_initializer=tf.contrib.layers.xavier_initializer_conv2d(), scope=scope, reuse=reuse)\n",
        "#       pool_1 = tf.contrib.layers.max_pool2d(conv_1, [1, 2], stride=[1, 2])\n",
        "#       flattened_1 = tf.contrib.layers.flatten(pool_1)\n",
        "#       dropout_1 = tf.contrib.layers.dropout(flattened_1, keep_prob=0.9)\n",
        "      \n",
        "    with tf.variable_scope('dense_1') as scope:\n",
        "      flattened_1 = tf.contrib.layers.flatten(output)\n",
        "      dropout_1 = tf.contrib.layers.dropout(flattened_1, keep_prob=0.9)\n",
        "      dense_1 = tf.contrib.layers.fully_connected(flattened_1, 200, activation_fn=tf.nn.sigmoid, \\\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer(), scope=scope, reuse=reuse)\n",
        "  return dense_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCp67YQZDMnw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ]
    },
    {
      "metadata": {
        "id": "RrBRDdVunc4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def contrastive_loss(model1, model2, label, margin):\n",
        "  with tf.name_scope('contrastive-loss'):\n",
        "    distance = tf.sqrt(tf.reduce_sum(tf.pow(model1 - model2, 2), 1, keepdims=True))\n",
        "    similarity = label * tf.square(distance)\n",
        "    dissimilarity = (1 - label) * tf.square(tf.maximum((margin - distance), 0))\n",
        "    print(distance)\n",
        "    print(similarity)\n",
        "    print(dissimilarity)\n",
        "    print(tf.nn.sigmoid(similarity - dissimilarity))\n",
        "  return tf.nn.sigmoid(similarity - dissimilarity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ewIvmzHF2UA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Inputs to the model"
      ]
    },
    {
      "metadata": {
        "id": "cWtiQaylvL-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X1 = tf.placeholder(dtype='float', shape=[None, max_length, num_features])\n",
        "X2 = tf.placeholder(dtype='float', shape=[None, max_length, num_features])\n",
        "y = tf.placeholder(dtype='float', shape=[None, 1])\n",
        "margin = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3kljT8GaF9S2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plug everything together"
      ]
    },
    {
      "metadata": {
        "id": "qcAm-hvPwqre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "fd2ab9d4-f276-40cb-89d2-02c94b325787"
      },
      "cell_type": "code",
      "source": [
        "model1 = model(X1, False)\n",
        "model2 = model(X2, True)\n",
        "\n",
        "loss = contrastive_loss(model1, model2, y, margin)\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss=loss)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-2e3452726e2d>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-18-2e3452726e2d>:7: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"contrastive-loss/Sqrt:0\", shape=(?, 1), dtype=float32)\n",
            "Tensor(\"contrastive-loss/mul:0\", shape=(?, 1), dtype=float32)\n",
            "Tensor(\"contrastive-loss/mul_1:0\", shape=(?, 1), dtype=float32)\n",
            "Tensor(\"contrastive-loss/Sigmoid:0\", shape=(?, 1), dtype=float32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XiBMTxV_IH9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38efbbd0-fba5-4c82-c059-0e2c0ec9eb1c"
      },
      "cell_type": "code",
      "source": [
        "print(model1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"model/dense_1/dense_1/Sigmoid:0\", shape=(?, 200), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DX6_tAMqIfCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b34ec16f-4f06-4fd6-dda6-84346a14e1a4"
      },
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sUYM0mghGEhb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ]
    },
    {
      "metadata": {
        "id": "keHumcYzrxBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "num_epochs = 2\n",
        "display_step = 1\n",
        "save_step = 1\n",
        "log_step = 1\n",
        "\n",
        "num_samples_tr = train.shape[0]\n",
        "num_samples_te = test.shape[0]\n",
        "num_batches_tr = int(math.ceil(num_samples_tr/batch_size))\n",
        "num_batches_te = int(math.ceil(num_samples_te/batch_size))\n",
        "\n",
        "train_loss = []\n",
        "test_loss = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C1ViimzPsGvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AF8-0ioesIc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "24460f49-f4b8-42a0-d472-af9276fab0ea"
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# saver.restore(sess, base_path_model + 'model_95.ckpt')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  loss_val = 0\n",
        "  for i in range(0, num_samples_tr, batch_size):\n",
        "    batch_x1, batch_x2, l1, l2, batch_y = next_batch(train, batch_size)\n",
        "    \n",
        "    _, lv = sess.run([train_op, loss], feed_dict={X1: batch_x1, X2: batch_x2, y: batch_y})\n",
        "    loss_val += lv\n",
        "    \n",
        "  if epoch % display_step == 0:\n",
        "    print(epoch, loss_val)\n",
        "  if epoch % save_step == 0:\n",
        "    saver.save(sess, base_path_model + 'model_' + str(epoch) + '.ckpt')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-0bad0a0f4900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (20,) for Tensor 'Placeholder_2:0', which has shape '(?, 1)'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7t5VQBfH1D3O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test model"
      ]
    },
    {
      "metadata": {
        "id": "NRB122xNGPku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}